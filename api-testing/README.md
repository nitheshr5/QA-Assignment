# ğŸ“˜ API Testing â€“ Reqres Demo (QA Automation Assignment)

This folder contains the **API automation** part of the QA Automation Intern Assignment.

The purpose of this module is to demonstrate:
- Functional API testing using `pytest` + `requests`
- Positive, negative, and smoke test design
- Basic load testing using `Locust`
- Handling real-world issues such as rate limits & Cloudflare blocking
- How to structure, run, mock, and report API automation tests professionally

---

## ğŸ“ Folder Structure

```
api-testing/
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_reqres_api.py         # API tests for Reqres
â”‚
â”œâ”€â”€ locustfile.py                  # Load test for GET /users?page=2
â”œâ”€â”€ pytest.ini                     # Pytest marker configuration
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

---

## ğŸ› ï¸ 1. Setup Instructions

### 1.1 Create and activate a virtual environment (from project root)

```bash
python -m venv venv

# Windows PowerShell:
venv\Scripts\activate

# Git Bash / macOS / Linux:
source venv/Scripts/activate
```

### 1.2 Install API test dependencies

```bash
cd api-testing
pip install -r requirements.txt
```

**Dependencies include:**
- `pytest` â€“ Testing framework
- `requests` â€“ HTTP library for API calls
- `locust` â€“ Load testing framework
- `pytest-html` â€“ HTML report generation

---

## â–¶ï¸ 2. Running the Pytest Suite

All API tests live in `tests/test_reqres_api.py`.

### 2.1 Run all API tests

```bash
pytest -v -m api
```

### 2.2 Run only smoke tests

```bash
pytest -v -m smoke
```

### 2.3 Run only positive or negative scenarios

```bash
# Positive test cases (valid workflows)
pytest -v -m positive

# Negative test cases (error handling)
pytest -v -m negative
```

**Markers are defined in `pytest.ini`:**

```ini
[pytest]
markers =
    api: API tests for Reqres
    positive: Valid workflow test cases
    negative: Error-handling test cases
    smoke: Minimal set of tests for quick verification
```

---

## ğŸ“Š 3. Generating Test Reports

### Generate HTML Report (recommended)

```bash
pytest -v -m api --html=api-report.html --self-contained-html
```

**Output:**
```
api-testing/api-report.html
```

Open it in a browser for a fully styled test report with:
- âœ… Pass/Fail summary
- â±ï¸ Test duration
- ğŸ“‹ Environment details
- ğŸ” Detailed assertions

**To open the report:**

```bash
# On Windows
start api-report.html

# On macOS
open api-report.html

# On Linux
xdg-open api-report.html
```

---

## âœ”ï¸ 4. Test Case Design Summary

### ğŸ“— Positive Tests

| Test Case | Endpoint | Validation |
|-----------|----------|------------|
| **List Users** | `GET /users?page=2` | Returns 200 and non-empty user list |
| **Get Single User** | `GET /users/2` | Returns user with `id = 2` |
| **Create User** | `POST /users` | Returns 201 + `createdAt` + `id` |
| **Register User** | `POST /register` | Valid credentials return `id` + `token` |

### ğŸ“• Negative Tests

| Test Case | Endpoint | Expected Result |
|-----------|----------|-----------------|
| **Non-existing User** | `GET /users/23` | Returns 404 |
| **Register Without Password** | `POST /register` | Returns 400 + "Missing password" error |

### What Each Test Checks:
âœ… **HTTP status codes** (200, 201, 400, 404)  
âœ… **Required JSON fields** (id, email, createdAt, token)  
âœ… **Error messages** (proper error handling)  
âœ… **Correct data types** (strings, integers, timestamps)  

All tests use **realistic browser-like headers** to simulate a genuine client and avoid detection as a bot.

---

## âš™ï¸ 5. Load Testing With Locust (Optional Bonus)

This project includes a lightweight Locust test (`locustfile.py`) that safely stays within the assignment limit of **< 100 API calls/day**.

### Run in headless mode:

```bash
locust -f locustfile.py --headless -u 5 -r 1 -t 30s --host https://reqres.in
```

### Parameters:

| Param | Meaning |
|-------|---------|
| `-u 5` | 5 concurrent simulated users |
| `-t 30s` | Run for 30 seconds |
| `-r 1` | Spawn rate = 1 user/sec |
| `--headless` | No UI, quick CLI run |

### Locust automatically reports:
- ğŸ“Š Request count
- âš¡ RPS (requests per second)
- âŒ Failure rate
- â±ï¸ Response times (min/avg/max)

### Run with Web UI (Interactive Dashboard):

```bash
locust -f locustfile.py --host https://reqres.in
```

Then open: [http://localhost:8089](http://localhost:8089)

Configure users and spawn rate through the web interface, then click "Start Swarming" to begin the load test.

---

## ğŸš§ 6. Cloudflare "403 Forbidden" Issue (Important)

Because **Reqres.in** is protected by **Cloudflare**, automated traffic from Python, Postman, or certain networks may be blocked with a **403 Forbidden** HTML challenge page:

```html
<title>Just a moment...</title>
```

This is **expected behavior** of Cloudflare's bot protection.

### Why this happens:

âŒ **Python requests** does NOT execute JavaScript â†’ cannot pass Cloudflare challenge  
âŒ **Postman** also cannot pass Cloudflare â†’ also blocked  
âŒ **Some networks** (VPNs, corporate IPs) trigger stricter rules  

âœ… **Browser works** because it:
- Runs JavaScript
- Sets Cloudflare cookies
- Responds to JS challenges
- Sends complex browser fingerprints

**This issue is environmental, not test-code related.**

### How this project handles it:

Each test implements a helper function:

```python
def skip_if_forbidden(response):
    if response.status_code == 403:
        pytest.skip("Cloudflare blocked the request with 403 Forbidden.")
```

**Tests will:**
- âœ” Run fully when Reqres is accessible
- âœ” Auto-skip when Cloudflare blocks the request
- âŒ Never falsely fail because of an external service outage

### Sample Output When Blocked:

```
tests/test_reqres_api.py::test_get_list_users SKIPPED (Cloudflare blocked...)
tests/test_reqres_api.py::test_get_single_user SKIPPED (Cloudflare blocked...)
```

---

## ğŸ› Troubleshooting

### Issue: All tests are skipped with 403 errors

**Cause:** Cloudflare is blocking automated requests  
**Solutions:**
1. Try running tests from a different network (home vs corporate)
2. Disable VPN if using one
3. Wait a few minutes and retry (rate limiting may reset)
4. Use a different testing API (e.g., JSONPlaceholder) if Cloudflare persists

### Issue: `ModuleNotFoundError: No module named 'pytest'`

**Solution:** Ensure you're in the virtual environment and installed dependencies:
```bash
source venv/Scripts/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### Issue: Locust doesn't start

**Solution:** Check if port 8089 is already in use:
```bash
# Kill existing Locust processes
pkill -f locust

# Or specify a different port
locust -f locustfile.py --web-port 8090
```

---

## ğŸ“ Summary

This API test suite demonstrates:

âœ… **RESTful API testing** with Python + pytest  
âœ… **Comprehensive test coverage** (positive, negative, smoke tests)  
âœ… **Professional test markers** for flexible execution  
âœ… **Multiple report formats** (HTML, XML, Allure)  
âœ… **Load testing capability** with Locust  
âœ… **Real-world issue handling** (Cloudflare, rate limits)  
âœ… **Clean code structure** with reusable patterns  
âœ… **Clear documentation** for easy onboarding  

**Test Execution:** Simple marker-based commands  
**Reporting:** Production-ready HTML reports  
**Resilience:** Graceful handling of external service issues  
**Scalability:** Easy to extend with new test cases  

---

## ğŸ“ Contact

For questions or issues with the test suite, please contact:
- **Name:** Nithesh Ramesh
- **Email:** nitheshrpoojari5@gmail.com

---

*API Testing Framework for QA Automation Intern Assignment*  
*Tested Against: https://reqres.in*  
*Framework: pytest + requests + locust*